[{"path":[]},{"path":"https://lwaldron.github.io/bios1/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"CC0 1.0 Universal","title":"CC0 1.0 Universal","text":"CREATIVE COMMONS CORPORATION LAW FIRM PROVIDE LEGAL SERVICES. DISTRIBUTION DOCUMENT CREATE ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES INFORMATION “-” BASIS. CREATIVE COMMONS MAKES WARRANTIES REGARDING USE DOCUMENT INFORMATION WORKS PROVIDED HEREUNDER, DISCLAIMS LIABILITY DAMAGES RESULTING USE DOCUMENT INFORMATION WORKS PROVIDED HEREUNDER.","code":""},{"path":"https://lwaldron.github.io/bios1/LICENSE.html","id":"statement-of-purpose","dir":"","previous_headings":"","what":"Statement of Purpose","title":"CC0 1.0 Universal","text":"laws jurisdictions throughout world automatically confer exclusive Copyright Related Rights (defined ) upon creator subsequent owner(s) (, “owner”) original work authorship /database (, “Work”). Certain owners wish permanently relinquish rights Work purpose contributing commons creative, cultural scientific works (“Commons”) public can reliably without fear later claims infringement build upon, modify, incorporate works, reuse redistribute freely possible form whatsoever purposes, including without limitation commercial purposes. owners may contribute Commons promote ideal free culture production creative, cultural scientific works, gain reputation greater distribution Work part use efforts others. /purposes motivations, without expectation additional consideration compensation, person associating CC0 Work (“Affirmer”), extent owner Copyright Related Rights Work, voluntarily elects apply CC0 Work publicly distribute Work terms, knowledge Copyright Related Rights Work meaning intended legal effect CC0 rights. Copyright Related Rights. Work made available CC0 may protected copyright related neighboring rights (“Copyright Related Rights”). Copyright Related Rights include, limited , following: right reproduce, adapt, distribute, perform, display, communicate, translate Work; moral rights retained original author(s) /performer(s); publicity privacy rights pertaining person’s image likeness depicted Work; rights protecting unfair competition regards Work, subject limitations paragraph 4(), ; rights protecting extraction, dissemination, use reuse data Work; database rights (arising Directive 96/9/EC European Parliament Council 11 March 1996 legal protection databases, national implementation thereof, including amended successor version directive); similar, equivalent corresponding rights throughout world based applicable law treaty, national implementations thereof. Waiver. greatest extent permitted , contravention , applicable law, Affirmer hereby overtly, fully, permanently, irrevocably unconditionally waives, abandons, surrenders Affirmer’s Copyright Related Rights associated claims causes action, whether now known unknown (including existing well future claims causes action), Work () territories worldwide, (ii) maximum duration provided applicable law treaty (including future time extensions), (iii) current future medium number copies, (iv) purpose whatsoever, including without limitation commercial, advertising promotional purposes (“Waiver”). Affirmer makes Waiver benefit member public large detriment Affirmer’s heirs successors, fully intending Waiver shall subject revocation, rescission, cancellation, termination, legal equitable action disrupt quiet enjoyment Work public contemplated Affirmer’s express Statement Purpose. Public License Fallback. part Waiver reason judged legally invalid ineffective applicable law, Waiver shall preserved maximum extent permitted taking account Affirmer’s express Statement Purpose. addition, extent Waiver judged Affirmer hereby grants affected person royalty-free, non transferable, non sublicensable, non exclusive, irrevocable unconditional license exercise Affirmer’s Copyright Related Rights Work () territories worldwide, (ii) maximum duration provided applicable law treaty (including future time extensions), (iii) current future medium number copies, (iv) purpose whatsoever, including without limitation commercial, advertising promotional purposes (“License”). License shall deemed effective date CC0 applied Affirmer Work. part License reason judged legally invalid ineffective applicable law, partial invalidity ineffectiveness shall invalidate remainder License, case Affirmer hereby affirms () exercise remaining Copyright Related Rights Work (ii) assert associated claims causes action respect Work, either case contrary Affirmer’s express Statement Purpose. Limitations Disclaimers. trademark patent rights held Affirmer waived, abandoned, surrendered, licensed otherwise affected document. Affirmer offers Work -makes representations warranties kind concerning Work, express, implied, statutory otherwise, including without limitation warranties title, merchantability, fitness particular purpose, non infringement, absence latent defects, accuracy, present absence errors, whether discoverable, greatest extent permissible applicable law. Affirmer disclaims responsibility clearing rights persons may apply Work use thereof, including without limitation person’s Copyright Related Rights Work. , Affirmer disclaims responsibility obtaining necessary consents, permissions rights required use Work. Affirmer understands acknowledges Creative Commons party document duty obligation respect CC0 use Work.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"source-code-and-data-for-this-assignment","dir":"Articles","previous_headings":"","what":"Source code and data for this assignment","title":"BIOS 1 - Homework 1","text":"Note: code used create document . homework use NHEFS dataset introduced week 4. Take look codebook linked https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/. Download dataset import R. Try using File - Import Dataset - text (readr) menu option import .  code directly import NHEFS dataset web. Note use knitr code chunk option cache=TRUE cache results locally avoid downloading web time run program.","code":"library(readr) nhefs <- read_csv(\"https://cdn1.sph.harvard.edu/wp-content/uploads/sites/1268/1268/20/nhefs.csv\") ## Rows: 1629 Columns: 64 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \",\" ## dbl (64): seqn, qsmk, death, yrdth, modth, dadth, sbp, dbp, sex, age, race, ... ##  ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-1-customizing-read_csv","dir":"Articles","previous_headings":"","what":"Question 1: customizing read_csv","title":"BIOS 1 - Homework 1","text":"Using help Import Dataset tool demonstrated , change read_csv command import factor (categorical) variables first 15 columns factors instead double (numeric). don’t need recode numeric values yet.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-2-recoding","dir":"Articles","previous_headings":"","what":"Question 2: recoding","title":"BIOS 1 - Homework 1","text":"use following variables. factors, use dplyr case_match function recode informative factor levels. yes/factors use “” reference category, factors use whichever common group reference category. active age education exercise race sex smokeintensity smkyrs wt82_71","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-3-table-1","dir":"Articles","previous_headings":"","what":"Question 3: Table 1","title":"BIOS 1 - Homework 1","text":"Use table1 package (alternative choice) make “Table 1” summarizing variables. Use table1::label command create informative labels variables table.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-4-draw-a-dag","dir":"Articles","previous_headings":"","what":"Question 4: draw a DAG","title":"BIOS 1 - Homework 1","text":"Use http://www.dagitty.net/ create DAG following hypothesis. Use R dagitty package display DAG document: wt82_71 caused qsmk (particular, quitting smoking causes weight gain) sex, race, age, education, exercise hypothesized confounders. Write words research hypothesis, using meanings variables rather just variable names. Also write words null hypothesis statistical testing. two-sided null hypothesis even case research hypothesis one-sided?","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-5-fit-a-regression-model","dir":"Articles","previous_headings":"","what":"Question 5: fit a regression model","title":"BIOS 1 - Homework 1","text":"Fit following multiple linear regression model (note age squared represented model formula (age^2)): \\[ wt82\\_71 \\sim qsmk + sex + race + age + age^2 + education + exercise \\] See https://www.oreilly.com/library/view/-r-book/9780470510247/ch009-sec009.html convenient summary use R model formulae.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-6-standardization","dir":"Articles","previous_headings":"","what":"Question 6: standardization","title":"BIOS 1 - Homework 1","text":"Calculate mean predicted outcomes treatment (quitting smoking) treatment (quitting smoking). Calculate difference estimate causal effect quitting smoking change weight. conditional average treatment effect estimated using standardization different coefficient qsmk table regression coefficients?","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-7-dag-and-regression-with-interactions","dir":"Articles","previous_headings":"","what":"Question 7: DAG and regression with interactions","title":"BIOS 1 - Homework 1","text":"Now suppose hypothesize smoking intensity also impacts weight loss, modifies effect quitting smoking weight loss. Draw new DAG incorporates hypothesized effects smoking intensity. Fit new linear regression model includes linear quadratic term smokeintensity (age) interaction qsmk smokeintensity.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-8-standardization-with-interactions","dir":"Articles","previous_headings":"","what":"Question 8: standardization with interactions","title":"BIOS 1 - Homework 1","text":"use standardization calculate conditional average treatment effect quitting smoking sample. estimate different coefficient qsmk new table regression coefficients Question 7?","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-9-bootstrap","dir":"Articles","previous_headings":"","what":"Question 9: bootstrap","title":"BIOS 1 - Homework 1","text":"Write function takes two arguments: function(x, d) : x dataframe tibble data d integer vector row IDs used choose subset dataframe, example using dplyr::slice(x, d) Using subset dplyr::slice(x, d), function perform calculation Question 8a, returning conditional average treatment effect model interaction term. Show output calling function using d = 1:nrow(x) confirm gives result 8a. Estimate 95% bootstrap confidence interval conditional average treatment effect, using least 1000 replications. welcome use favorite method implement bootstrap, recommend boot library powerful simpler use programming simulation. Summarize findings. effect quitting smoking weight change significant? effect? modified baseline smoking intensity?","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework1.html","id":"question-10-what-did-those-quadratic-terms-do","dir":"Articles","previous_headings":"","what":"Question 10: what did those quadratic terms do?","title":"BIOS 1 - Homework 1","text":"Use coefficients age (age)^2 plot conditional relationship age weight change participants study. Specifically, use ages participants study calculate \\[ y = \\beta_{age} * age + \\beta_{(age)^2} * age^2 \\] create scatterplot y vs age. quadratic term change modeled association age weight change, compared linear term ?","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework2.html","id":"source-code-and-data-for-this-assignment","dir":"Articles","previous_headings":"","what":"Source code and data for this assignment","title":"BIOS 1 - Homework 2","text":"Note: code used create document . homework use NHEFS dataset. Take look codebook linked https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/. time test hypothesis quitting smoking 1971 1981 (variable qsmk) reduces probability death 2001 (variable death).","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework2.html","id":"data-import-and-recoding","dir":"Articles","previous_headings":"","what":"Data import and recoding","title":"BIOS 1 - Homework 2","text":"Download dataset, import R, recode variables instructed Homework 1.","code":"library(readr) nhefs <- read_csv(\"https://cdn1.sph.harvard.edu/wp-content/uploads/sites/1268/1268/20/nhefs.csv\")"},{"path":"https://lwaldron.github.io/bios1/articles/Homework2.html","id":"question-1-2-points-filter-any-missing-data","dir":"Articles","previous_headings":"","what":"Question 1 (2 points): filter any missing data","title":"BIOS 1 - Homework 2","text":"Remove observations missing following variables: death active age education exercise qsmk race sex smokeintensity smkyrs wt82_71 ordinarily want perform sensitivity analysis consider possibility bias informative censoring, can ignore possibility purposes assignment.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework2.html","id":"question-2-4-points-table-1","dir":"Articles","previous_headings":"","what":"Question 2 (4 points): Table 1","title":"BIOS 1 - Homework 2","text":"Create table descriptive statistics like HW1, time stratify exposure variable qsmk","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework2.html","id":"question-3-4-points-fit-crude-and-adjusted-logistic-regression-models","dir":"Articles","previous_headings":"","what":"Question 3 (4 points): fit crude and adjusted logistic regression models","title":"BIOS 1 - Homework 2","text":"Fit simple adjusted multiple logistic regression models probability death quitting smoking exposure. multivariate model, adjust sex, race, age, education, exercise hypothesized confounders. Use B-spline splines package correct age, ie: \\[ death \\sim qsmk + sex + race + bs(age) + education + exercise \\] purpose question, assume conditional exchangeability holds controlling confounders. Interpret coefficient qsmk crude model adjusted model. Compare .","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework2.html","id":"question-4-3-points-model-diagnostics","dir":"Articles","previous_headings":"","what":"Question 4 (3 points): model diagnostics","title":"BIOS 1 - Homework 2","text":"Create binned residual plot using binnedplot function arm library. Interpret plot.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Homework2.html","id":"question-5-7-points-inverse-probability-weighting","dir":"Articles","previous_headings":"","what":"Question 5 (7 points): Inverse probability weighting","title":"BIOS 1 - Homework 2","text":"(2 points)) Create model calculate propensity exposure given values hypothesized confounders (propensity score). “denominator” model Lecture 11, Slide 15. ie, \\[ \\textbf{denom.fit}:qsmk \\sim sex + race + bs(age) + education + exercise \\] Also fit “numerator model”, \\[ \\textbf{num.fit}: qsmk \\sim 1 \\] b (2 points)) Calculate IPTW weights using model. Hint - can use code like : c (2 points)) Use geeglm function geepack library use weights estimate causal effect quitting smoking death. Notes: - id argument geepack arbitrary case grouping hierarchical structure participants. can use seqn variable 1:nrow(nhefs). - corstr argument also arbitrary reason; use corstr=\"unstructured\" - Remember using weights, include confounders model. d (1 point)) Compare coefficient standard error quitting smoking Question 2, comment. Recall discussion lecture geepack standard errors conservative.","code":"pdenom <- predict(denom.fit, type = \"response\") pnum <- predict(num.fit, type = \"response\") nhefs$iptw <- ifelse(nhefs$qsmk == 0, ((1-pn.qsmk)/(1-pd.qsmk)),                      (pn.qsmk/pd.qsmk))"},{"path":"https://lwaldron.github.io/bios1/articles/Lab5.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Lab 5: Writing and debugging a function in R","text":"lab, learn write simple function R use browser() command debug . Debugging crucial step development process software. involves finding fixing errors bugs code. browser() command allows stop execution code specific point inspect values variables objects.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab5.html","id":"loading-data","dir":"Articles","previous_headings":"","what":"Loading data","title":"Lab 5: Writing and debugging a function in R","text":"use NHANES library provides small subset National Health Nutrition Examination data (https://wwwn.cdc.gov/nchs/nhanes/Default.aspx). Install load “NHANES” dataset find help page contains codebook. include evaluated install.package() Rmd program. can happen ? “Description” section help page “NHANES” object?","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab5.html","id":"viewing-the-data","dir":"Articles","previous_headings":"Loading data","what":"Viewing the data","title":"Lab 5: Writing and debugging a function in R","text":"Note following command interactive use , show can use eval = FALSE command code chunk. can happen evaluated View() command .Rmd file?","code":"View(NHANES)"},{"path":"https://lwaldron.github.io/bios1/articles/Lab5.html","id":"summarizing-the-data","dir":"Articles","previous_headings":"","what":"Summarizing the data","title":"Lab 5: Writing and debugging a function in R","text":"Use summary() function summarize dataset. many missing values weight height?","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab5.html","id":"writing-a-function","dir":"Articles","previous_headings":"","what":"Writing a Function","title":"Lab 5: Writing and debugging a function in R","text":"Let’s write function takes two arguments: 1. df dataframe two columns numeric data 2. integer vector indices corresponding rows dataframe used calculation function filters dataframe rows missing values, returns difference mean first column minus mean second column. Hint: start calculation weight height columns NHANES dataset, copy working code function.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab5.html","id":"debugging-with-the-browser-command","dir":"Articles","previous_headings":"","what":"Debugging with the Browser Command","title":"Lab 5: Writing and debugging a function in R","text":"function working without error, create error intentionally. example, pass character value argument . Now want use browser() command debug function. browser() command stop execution function specific point allow us inspect values variables objects. Insert browser() command first line inside function, pass new function definition R console. Use ls() “Environment” tab see variables visible new environment within function. variables see? ? changed entered function? figured caused error, exit browser using Q, remove browser command function, re-define without containing browser().","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab5.html","id":"write-another-function","dir":"Articles","previous_headings":"","what":"Write another function","title":"Lab 5: Writing and debugging a function in R","text":"Write another function takes input arguments, returns difference mean weight males minus mean weight females.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab6.html","id":"learning-objectives","dir":"Articles","previous_headings":"","what":"Learning Objectives","title":"Lab 6: Image analysis to predict malignant breast cancer using logistic regression","text":"Identify correct problematic data file perform exploratory data analysis binary variable perform logistic regression R using glm() function identify collinearity among many numeric variables interpret logistic regression coefficients predictive setting use logistic regression model predict probabilities binary outcome use tidyr pivot wide format long format dataframe use ggplot2’s facet_wrap() create multiple plots overlay line plot predicted probabilities xy plot data points","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab6.html","id":"materials","dir":"Articles","previous_headings":"","what":"Materials","title":"Lab 6: Image analysis to predict malignant breast cancer using logistic regression","text":"RStudio R environment Dataset: breast cancer.csv (download). dataset contains outcome variable “diagnosis” values B (benign) M (malignant), number cellular pathologic features representing properties cells calculated image analysis algorithm. row corresponds patient underwent tissue biopsy. information dataset interested. R packages: readr, dplyr, ggplot2, tidyr, possibly ComplexHeatmap","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab6.html","id":"importing-the-dataset","dir":"Articles","previous_headings":"","what":"1. Importing the Dataset","title":"Lab 6: Image analysis to predict malignant breast cancer using logistic regression","text":"Import dataset (breast cancer.csv) R, using readr. problem 33rd column causing warning? Fix problem data file, try . Import id character, diagnosis factor values B M. Recode “diagnosis” column informative values “benign” “malignant”, reference level “benign”","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab6.html","id":"exploratory-data-analysis-eda","dir":"Articles","previous_headings":"","what":"2. Exploratory Data Analysis (EDA)","title":"Lab 6: Image analysis to predict malignant breast cancer using logistic regression","text":"part question, write something notice data exploration, variable type, missing values. right/wrong answers , just get practice interpreting EDA. Check dimensions dataset using dim() function Preview first rows dataset using head() function Use summary() summarize dataset. Identify collinear variables. following command, run wide dataframe, calculate 1 minus pairwise Pearson correlation pair numeric variables dataset. represents distance matrix variables, “0” means two variables identical perfectly anti-correlated, “1” means two variables zero correlation. use 1 minus absolute value correlations becomes distance measure instead correlation measure. Plot distance matrix identify highly correlated anticorrelated variables. ways (distance matrix called d) follows - try choose favorite. may want increase size figure output . : : Note, ComplexHeatmap Bioconductor package. can install follows: pheatmap (“pretty heatmap”) normal CRAN package works well can use instead, ComplexHeatmap powerful heatmap package available time writing lab. Create box plot column except id. boxplot two boxes, one benign one malignant, allowing visual comparison distribution variable benign malignant specimens. variables clearly association breast cancer diagnosis? Hints e: Create new dataset without id variable, use tidyr::pivot_longer function create “long” dataframe 3 columns: 1. diagnosis, 2. name column “wide” dataframe, 3. column containing numeric values. first example pivot_longer help page (“Simplest case column names character data”) exactly analogous need . “long” dataset can add facet_wrap() command ggplot create box plot variable grid. Use scales argument use “free” scales box plot can different scale, can read box plot. Use knitr chunk options fig.width=10 fig.height=10 increase size figure make theaxis labels readable.","code":"plot(hclust(as.dist(d))) ComplexHeatmap::Heatmap(d) ComplexHeatmap::pheatmap(d) install.packages(\"BiocManager\") BiocManager::install(\"ComplexHeatmap\")"},{"path":"https://lwaldron.github.io/bios1/articles/Lab6.html","id":"building-a-logistic-regression-model","dir":"Articles","previous_headings":"","what":"3. Building a Logistic Regression Model","title":"Lab 6: Image analysis to predict malignant breast cancer using logistic regression","text":"Fit univariate logistic regression model using area_mean predictor diagnosis outcome, using glm() function Print summary model using summary() function Interpret coefficients logistic regression model","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Lab6.html","id":"making-predictions","dir":"Articles","previous_headings":"","what":"4. Making predictions","title":"Lab 6: Image analysis to predict malignant breast cancer using logistic regression","text":"Create xy plot area_mean x axis diagnosis y axis. Use geom_jitter(width = 0) create spread y-axis can see points without changing x values. Now add plot predicted probabilities observed temperature, using predict function argument type=\"response\". Hint: First add column predicted probabilities breast_cancer dataframe. add 1 probabilities make scale data points. can add geom_line() previous plot, aes(), add line. Suggestion: Change line color increase width make visible. notice data points predicted probabilities 0, 0.5, 1? predicted probabilities malignant diagnosis area_mean 300, 500, 700, 900, 1100?","code":""},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing data","title":"Tutorial 5","text":"tutorial supposed teach load dataset “clean” data (.e. rename variables levels variables, remove irrelevant variables, code missing data etc.) dataset, click File, “Import Dataset” “Text (Readr)”. Choose file show preview dataset. top, see variable names next little arrow. Click can choose different variable types, example “character” text data, “double” numeric data, “factor” variables 0 1. can also skip variables want imported. click “Import”, copy code bottom right paste code chunk R Markdown document. Import dataset “diabetes” described choose correct variable type variable. Paste code copy readr :","code":"library(tidyverse) library(readr) diabetes <-   read_csv(     \"datafiles/diabetes.csv\",     col_types = cols(Pregnancies = col_integer(),                      Outcome = col_factor(levels = c(\"0\", \"1\")))   )"},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"exercise-1-troubleshooting","dir":"Articles","previous_headings":"","what":"Exercise 1: Troubleshooting","title":"Tutorial 5","text":"one column imported character variable, numeric. ? Fix data file, import . Solution: see supposedly numeric column actually character using summary(). See observations column numeric coercing column numeric using .numeric(). Inspect value source data file re-type correctly. Row 28 (observation 27) DiabetesPedigreeFunction letter “O” instead numeric “0”. Alternatively leave source file alone, correct reading:","code":"library(readr) diabetes <-   read_csv(     \"https://github.com/lwaldron/bios1/raw/main/vignettes/datafiles/diabetes.csv\",     col_types = cols(Pregnancies = col_integer(),                      Outcome = col_factor(levels = c(\"0\", \"1\")))   ) diabetes <- mutate(diabetes,        DiabetesPedigreeFunction = stringr::str_replace_all(DiabetesPedigreeFunction, \"O\", \"0\"),        DiabetesPedigreeFunction = as.numeric(DiabetesPedigreeFunction)        ) summary(diabetes$DiabetesPedigreeFunction) # now numeric with no missing values! ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  ##  0.0780  0.2437  0.3725  0.4719  0.6262  2.4200"},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"recode-impossible-variable-values-as-missing","dir":"Articles","previous_headings":"","what":"Recode impossible variable values as missing","title":"Tutorial 5","text":"Part data cleaning sometimes recoding impossible variable values missing. example, blood pressure values “0” “-99” “999” impossible represent missing values. Use dplyr’s case_when case_match functions recode impossible values NA. Inspect histograms numeric column, frequency tables categorical column, order assess validity values. fixes just one numeric variables problems, BloodPressure. also recodes Outcome “diabetes” “diabetes”, “diabetes” reference category.","code":"library(dplyr) diabetes2 <- diabetes %>%   mutate(BloodPressure = case_when(BloodPressure >  300 ~ NA,                                    BloodPressure < 20 ~ NA,                                    .default = as.numeric(BloodPressure))) %>%   mutate(Outcome = case_match(Outcome, \"1\" ~ \"diabetes\",                               \"0\" ~ \"no diabetes\",                               .ptype = factor(levels = c(\"no diabetes\", \"diabetes\"))))"},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"subsetting","dir":"Articles","previous_headings":"","what":"Subsetting","title":"Tutorial 5","text":"Create subset, example participants exactly 1 pregnancy.","code":"dplyr::filter(diabetes, Pregnancies == 1) |>   pull(Pregnancies) |>   table() ##  ##   1  ## 135"},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"keepremoverename-variables-manually","dir":"Articles","previous_headings":"","what":"Keep/Remove/Rename variables manually","title":"Tutorial 5","text":"can also add remove variables imported dataset dplyr::select function (see code ). dplyr::rename() function can used change name variable. always follows structure: * old name = new name","code":"library(dplyr) select(diabetes, c(BMI, Glucose, Insulin)) %>%   summary() #this only keeps these three variables ##       BMI           Glucose         Insulin      ##  Min.   : 0.00   Min.   :  0.0   Min.   :  0.0   ##  1st Qu.:27.30   1st Qu.: 99.0   1st Qu.:  0.0   ##  Median :32.00   Median :117.0   Median : 30.5   ##  Mean   :31.99   Mean   :120.9   Mean   : 79.8   ##  3rd Qu.:36.60   3rd Qu.:140.2   3rd Qu.:127.2   ##  Max.   :67.10   Max.   :199.0   Max.   :846.0 select(diabetes, -Pregnancies) %>%    summary() #this removes the Pregnancy variable ##     Glucose      BloodPressure     SkinThickness      Insulin      ##  Min.   :  0.0   Min.   :   0.00   Min.   : 0.00   Min.   :  0.0   ##  1st Qu.: 99.0   1st Qu.:  62.00   1st Qu.: 0.00   1st Qu.:  0.0   ##  Median :117.0   Median :  72.00   Median :23.00   Median : 30.5   ##  Mean   :120.9   Mean   :  82.03   Mean   :20.54   Mean   : 79.8   ##  3rd Qu.:140.2   3rd Qu.:  80.00   3rd Qu.:32.00   3rd Qu.:127.2   ##  Max.   :199.0   Max.   :9999.00   Max.   :99.00   Max.   :846.0   ##       BMI        DiabetesPedigreeFunction      Age        Outcome ##  Min.   : 0.00   Min.   :0.0780           Min.   :21.00   0:500   ##  1st Qu.:27.30   1st Qu.:0.2437           1st Qu.:24.00   1:268   ##  Median :32.00   Median :0.3725           Median :29.00           ##  Mean   :31.99   Mean   :0.4719           Mean   :33.24           ##  3rd Qu.:36.60   3rd Qu.:0.6262           3rd Qu.:41.00           ##  Max.   :67.10   Max.   :2.4200           Max.   :81.00 rename(diabetes, BodyMassIndex = BMI) %>%    colnames() #this renames the old variable \"BMI\" to \"BodyMassIndex\" ## [1] \"Pregnancies\"              \"Glucose\"                  ## [3] \"BloodPressure\"            \"SkinThickness\"            ## [5] \"Insulin\"                  \"BodyMassIndex\"            ## [7] \"DiabetesPedigreeFunction\" \"Age\"                      ## [9] \"Outcome\""},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"exercise-2","dir":"Articles","previous_headings":"","what":"Exercise 2","title":"Tutorial 5","text":"Create diabetes dataset includes Outcome, Insulin, Glucose, Age, BMI rename Glucose “blood_glucose” Solution:","code":"diabetes2 %>%   rename(blood_glucose = Glucose) %>%   select(c(Outcome, Insulin, blood_glucose, Age, BMI)) ## # A tibble: 768 × 5 ##    Outcome     Insulin blood_glucose   Age   BMI ##    <fct>         <dbl>         <dbl> <dbl> <dbl> ##  1 diabetes          0           148    50  33.6 ##  2 no diabetes       0            85    31  26.6 ##  3 diabetes          0           183    32  23.3 ##  4 no diabetes      94            89    21  28.1 ##  5 diabetes        168           137    33  43.1 ##  6 no diabetes       0           116    30  25.6 ##  7 diabetes         88            78    26  31   ##  8 no diabetes       0           115    29  35.3 ##  9 diabetes        543           197    53  30.5 ## 10 diabetes          0           125    54   0   ## # ℹ 758 more rows"},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"change-variable-type","dir":"Articles","previous_headings":"","what":"Change variable type","title":"Tutorial 5","text":"cases want change variable type. example, variable 0 1, since numeric stand two different levels variable (e.g. female male) want convert factor.","code":"# another way to convert a variable to a factor with informative labels diabetes3 <-   mutate(diabetes, Outcome = factor(Outcome, levels = 0:1, labels = c(\"no\", \"yes\"))) table(diabetes$Outcome, diabetes3$Outcome) ##     ##      no yes ##   0 500   0 ##   1   0 268 summary(diabetes3$Outcome) #note the first value listed is the reference category ##  no yes  ## 500 268 levels(diabetes3$Outcome) #again the first value listed is the reference category ## [1] \"no\"  \"yes\""},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"delete-na-or-missing-data","dir":"Articles","previous_headings":"","what":"Delete NA or missing data","title":"Tutorial 5","text":"Note never delete missing data creating Table 1 (ie missingness included table descriptive statistics). analysis several ways deal missingness, including: * multiple imputation * factors, treating missing values distinct factor level * removal observations missing values variables interest (ie outcome covariates regression model) can use following code delete observations missing data (“NA”). done already selected columns interest, otherwise might remove rows missing irrelevant variables. Note, recommended use integer values represent missingness. R NA . command remove missing values coded NA.","code":"diabetes %>% dim() ## [1] 768   9 diabetes %>%    na.omit() %>%   dim() ## [1] 768   9"},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"exercise-3","dir":"Articles","previous_headings":"","what":"Exercise 3","title":"Tutorial 5","text":"Create dataset diabetes dataset Elderly adults older 60 years.","code":"# before pull(diabetes2, Age) %>%   summary() ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  ##   21.00   24.00   29.00   33.24   41.00   81.00 # after dplyr::filter(diabetes2, Age > 60) %>%   pull(Age) %>%   summary() ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  ##   61.00   63.00   65.00   65.74   67.00   81.00"},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"rename-levels-of-your-variable","dir":"Articles","previous_headings":"","what":"Rename levels of your variable","title":"Tutorial 5","text":"may want re-name levels variable. first, check levels level order levels() function. see Outcome variable two levels: 0 1. datasets codebook states 0 1 stand . , 0 stands diabetes diagnosis 1 stands diabetes diagnosis. make easier, can rename levels following code:","code":"levels(diabetes2$Outcome) ## [1] \"no diabetes\" \"diabetes\" levels(diabetes2$Outcome) <- c(\"no diagnosis\", \"diagnosis\") summary(diabetes2$Outcome) ## no diagnosis    diagnosis  ##          500          268 # alternatively diabetes %>%   mutate(Outcome = factor(case_match(Outcome,                               \"0\" ~ \"No diagnosis\",                               \"1\" ~ \"diagnosis\"), # I specify levels here in order to make \"No diagnosis\" the reference # category - otherwise whichever label comes first alphabetically will be # the reference.                           levels = c(\"No diagnosis\", \"diagnosis\"))   ) %>%   pull(Outcome) %>%   summary() #the first one listed is the reference category ## No diagnosis    diagnosis  ##          500          268"},{"path":"https://lwaldron.github.io/bios1/articles/Tutorial5.html","id":"exercise-4","dir":"Articles","previous_headings":"","what":"Exercise 4","title":"Tutorial 5","text":"Now experience cleaning data, try following exercise: Create dataset diabetes dataset following characteristics: Drop variable DiabetesPedigreeFunction (keep variables) Age 20-60 Outcome factor 0 = diabetes 1 = diabetes Insulin, Skin Thickness, Blood Pressure = 0 recoded NA impossible values coded NA BMI 15 40","code":""},{"path":"https://lwaldron.github.io/bios1/articles/cancer_reg.html","id":"load-data","dir":"Articles","previous_headings":"","what":"Load data","title":"Cancer Death vs Poverty by County in US","text":"Read directly URL rename one column. Load data: See summary: Rename “TARGET_deathRate” column “cancer_death_rate”: Make scatter plot, giving points alpha=25% opacity:","code":"cancer_reg <- readr::read_csv(\"https://raw.githubusercontent.com/Arnab777as3uj/STAT6021-Cancer-Prediction-Project/master/cancer_reg.csv\") #> Rows: 3047 Columns: 34 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr  (2): binnedInc, Geography #> dbl (32): avgAnnCount, avgDeathsPerYear, TARGET_deathRate, incidenceRate, me... #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. summary(cancer_reg) #>   avgAnnCount      avgDeathsPerYear TARGET_deathRate incidenceRate    #>  Min.   :    6.0   Min.   :    3    Min.   : 59.7    Min.   : 201.3   #>  1st Qu.:   76.0   1st Qu.:   28    1st Qu.:161.2    1st Qu.: 420.3   #>  Median :  171.0   Median :   61    Median :178.1    Median : 453.5   #>  Mean   :  606.3   Mean   :  186    Mean   :178.7    Mean   : 448.3   #>  3rd Qu.:  518.0   3rd Qu.:  149    3rd Qu.:195.2    3rd Qu.: 480.9   #>  Max.   :38150.0   Max.   :14010    Max.   :362.8    Max.   :1206.9   #>                                                                       #>    medIncome        popEst2015       povertyPercent   studyPerCap      #>  Min.   : 22640   Min.   :     827   Min.   : 3.20   Min.   :   0.00   #>  1st Qu.: 38882   1st Qu.:   11684   1st Qu.:12.15   1st Qu.:   0.00   #>  Median : 45207   Median :   26643   Median :15.90   Median :   0.00   #>  Mean   : 47063   Mean   :  102637   Mean   :16.88   Mean   : 155.40   #>  3rd Qu.: 52492   3rd Qu.:   68671   3rd Qu.:20.40   3rd Qu.:  83.65   #>  Max.   :125635   Max.   :10170292   Max.   :47.40   Max.   :9762.31   #>                                                                        #>   binnedInc           MedianAge      MedianAgeMale   MedianAgeFemale #>  Length:3047        Min.   : 22.30   Min.   :22.40   Min.   :22.30   #>  Class :character   1st Qu.: 37.70   1st Qu.:36.35   1st Qu.:39.10   #>  Mode  :character   Median : 41.00   Median :39.60   Median :42.40   #>                     Mean   : 45.27   Mean   :39.57   Mean   :42.15   #>                     3rd Qu.: 44.00   3rd Qu.:42.50   3rd Qu.:45.30   #>                     Max.   :624.00   Max.   :64.70   Max.   :65.70   #>                                                                      #>   Geography         AvgHouseholdSize PercentMarried   PctNoHS18_24   #>  Length:3047        Min.   :0.0221   Min.   :23.10   Min.   : 0.00   #>  Class :character   1st Qu.:2.3700   1st Qu.:47.75   1st Qu.:12.80   #>  Mode  :character   Median :2.5000   Median :52.40   Median :17.10   #>                     Mean   :2.4797   Mean   :51.77   Mean   :18.22   #>                     3rd Qu.:2.6300   3rd Qu.:56.40   3rd Qu.:22.70   #>                     Max.   :3.9700   Max.   :72.50   Max.   :64.10   #>                                                                      #>    PctHS18_24   PctSomeCol18_24 PctBachDeg18_24   PctHS25_Over   #>  Min.   : 0.0   Min.   : 7.10   Min.   : 0.000   Min.   : 7.50   #>  1st Qu.:29.2   1st Qu.:34.00   1st Qu.: 3.100   1st Qu.:30.40   #>  Median :34.7   Median :40.40   Median : 5.400   Median :35.30   #>  Mean   :35.0   Mean   :40.98   Mean   : 6.158   Mean   :34.80   #>  3rd Qu.:40.7   3rd Qu.:46.40   3rd Qu.: 8.200   3rd Qu.:39.65   #>  Max.   :72.5   Max.   :79.00   Max.   :51.800   Max.   :54.80   #>                 NA's   :2285                                     #>  PctBachDeg25_Over PctEmployed16_Over PctUnemployed16_Over PctPrivateCoverage #>  Min.   : 2.50     Min.   :17.60      Min.   : 0.400       Min.   :22.30      #>  1st Qu.: 9.40     1st Qu.:48.60      1st Qu.: 5.500       1st Qu.:57.20      #>  Median :12.30     Median :54.50      Median : 7.600       Median :65.10      #>  Mean   :13.28     Mean   :54.15      Mean   : 7.852       Mean   :64.35      #>  3rd Qu.:16.10     3rd Qu.:60.30      3rd Qu.: 9.700       3rd Qu.:72.10      #>  Max.   :42.20     Max.   :80.10      Max.   :29.400       Max.   :92.30      #>                    NA's   :152                                                #>  PctPrivateCoverageAlone PctEmpPrivCoverage PctPublicCoverage #>  Min.   :15.70           Min.   :13.5       Min.   :11.20     #>  1st Qu.:41.00           1st Qu.:34.5       1st Qu.:30.90     #>  Median :48.70           Median :41.1       Median :36.30     #>  Mean   :48.45           Mean   :41.2       Mean   :36.25     #>  3rd Qu.:55.60           3rd Qu.:47.7       3rd Qu.:41.55     #>  Max.   :78.90           Max.   :70.7       Max.   :65.10     #>  NA's   :609                                                  #>  PctPublicCoverageAlone    PctWhite         PctBlack          PctAsian       #>  Min.   : 2.60          Min.   : 10.20   Min.   : 0.0000   Min.   : 0.0000   #>  1st Qu.:14.85          1st Qu.: 77.30   1st Qu.: 0.6207   1st Qu.: 0.2542   #>  Median :18.80          Median : 90.06   Median : 2.2476   Median : 0.5498   #>  Mean   :19.24          Mean   : 83.65   Mean   : 9.1080   Mean   : 1.2540   #>  3rd Qu.:23.10          3rd Qu.: 95.45   3rd Qu.:10.5097   3rd Qu.: 1.2210   #>  Max.   :46.60          Max.   :100.00   Max.   :85.9478   Max.   :42.6194   #>                                                                              #>   PctOtherRace     PctMarriedHouseholds   BirthRate      #>  Min.   : 0.0000   Min.   :22.99        Min.   : 0.000   #>  1st Qu.: 0.2952   1st Qu.:47.76        1st Qu.: 4.521   #>  Median : 0.8262   Median :51.67        Median : 5.381   #>  Mean   : 1.9835   Mean   :51.24        Mean   : 5.640   #>  3rd Qu.: 2.1780   3rd Qu.:55.40        3rd Qu.: 6.494   #>  Max.   :41.9303   Max.   :78.08        Max.   :21.326   #> cancer_reg <- dplyr::rename(cancer_reg, \"cancer_death_rate\" = \"TARGET_deathRate\") ggplot(cancer_reg, aes(x = povertyPercent, y = cancer_death_rate)) +   geom_point(alpha = 0.25) +   xlab(\"Poverty Percentage\") +   ylab(\"Cancer Death Rate\") +   ggtitle(\"Cancer Death vs Poverty by County in US\")"},{"path":"https://lwaldron.github.io/bios1/articles/standardization_simplified.html","id":"simulate-some-data","dir":"Articles","previous_headings":"","what":"Simulate some data","title":"Standardization simplified","text":"simulate sample 20 participants observations : * sex (M F) * height cm (random normal distribution mean 180cm standard deviation 10 cm), plus 5cm males * weight outcome variable, equal 0.2 * height, minus 2 treatment group, plus noise standard deviation equal 1 (N(0, 1))","code":"set.seed(1) df <- data.frame(   sex = c(rep(\"M\", 10), rep(\"F\", 10)),   group = sample(c(rep(\"trt\", 10), rep(\"placebo\", 10))) ) df$height = rnorm(20, mean = 180, sd = 10) + ifelse(df$sex == \"M\", 5, 0) df$weight = df$height * 0.2 - ifelse(df$group == \"trt\", 2, 0) + rnorm(20)"},{"path":"https://lwaldron.github.io/bios1/articles/standardization_simplified.html","id":"estimate-the-effect-of-treatment-using-regression","dir":"Articles","previous_headings":"","what":"Estimate the effect of treatment using regression","title":"Standardization simplified","text":"","code":"mod <- lm(weight ~ group + height + sex, data = df) summary(mod) ##  ## Call: ## lm(formula = weight ~ group + height + sex, data = df) ##  ## Residuals: ##     Min      1Q  Median      3Q     Max  ## -1.2803 -0.6890  0.2467  0.5510  1.0991  ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept)  2.00218    5.44217   0.368   0.7178     ## grouptrt    -2.65104    0.38109  -6.956 3.23e-06 *** ## height       0.18876    0.03046   6.197 1.28e-05 *** ## sexM         0.82686    0.37541   2.203   0.0426 *   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.8304 on 16 degrees of freedom ## Multiple R-squared:  0.8349, Adjusted R-squared:  0.8039  ## F-statistic: 26.97 on 3 and 16 DF,  p-value: 1.703e-06"},{"path":"https://lwaldron.github.io/bios1/articles/standardization_simplified.html","id":"estimate-the-effect-of-treatment-using-standardization","dir":"Articles","previous_headings":"","what":"Estimate the effect of treatment using standardization","title":"Standardization simplified","text":"Need create new datasets everyone treated, everyone received placebo. average weight everyone received treatment? average weight everyone received placebo? causal effect treatment compared placebo sample?","code":"newdatatrt <- df newdatatrt$group <- \"trt\" #everyone treated newdataplacebo <- df newdataplacebo$group <- \"placebo\" #everyone placebo (trtmean <- mean(predict(mod, newdata = newdatatrt))) ## [1] 33.8674 (placebomean <- mean(predict(mod, newdata = newdataplacebo))) ## [1] 36.51843 trtmean - placebomean ## [1] -2.651035"},{"path":"https://lwaldron.github.io/bios1/articles/standardization_simplified.html","id":"discussion","dir":"Articles","previous_headings":"","what":"Discussion","title":"Standardization simplified","text":"compare estimate regression table? ’s . interactions treatment, find standardized mean treatment effect anywhere table regression coefficients. Example: treatment different effect males females, regression table show effect reference sex. add coefficient interaction term sex get effect treatment non-reference sex. standardized effect average effect composition males females found sample. average treatment effect recalculated composition males females.","code":""},{"path":"https://lwaldron.github.io/bios1/articles/standardization_simplified.html","id":"why-standardization-then","dir":"Articles","previous_headings":"","what":"Why standardization then?","title":"Standardization simplified","text":"interactions treatment, effect treatment regression output reference group, average treatment effect sample. can standardize different samples population, distribution covariates different sample, even presence interactions. Standardization easily amenable bootstrap simulation estimate confidence intervals.","code":""},{"path":"https://lwaldron.github.io/bios1/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Levi Waldron. Author, maintainer. Zach Shahn. Author. Marcel Ramos. Author.","code":""},{"path":"https://lwaldron.github.io/bios1/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Waldron L, Shahn Z, Ramos M (2023). bios1: Code CUNY Biostatistics . R package version 0.0.0.9000, https://lwaldron.github.io/bios1/.","code":"@Manual{,   title = {bios1: Code for CUNY Biostatistics I},   author = {Levi Waldron and Zach Shahn and Marcel Ramos},   year = {2023},   note = {R package version 0.0.0.9000},   url = {https://lwaldron.github.io/bios1/}, }"},{"path":"https://lwaldron.github.io/bios1/index.html","id":"code-for-cuny-sph-applied-biostatistics-i","dir":"","previous_headings":"","what":"Code for CUNY Biostatistics I","title":"Code for CUNY Biostatistics I","text":"repository provides code lectures, labs, etc CUNY SPH Applied Biostatistics . source GitHub repository website “articles” vignettes directory shown compiled form.","code":""}]
